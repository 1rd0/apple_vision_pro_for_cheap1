{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPDNvpyEaDUQ0132PUBMUtx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1rd0/apple_vision_pro_for_cheap1/blob/main/%D0%9F%D1%80%D0%B5%D0%B4%D0%B8%D0%BA%D1%82_%D1%82%D1%80%D0%B5%D1%82%D0%B8%D1%87%D0%BD%D0%BE%D0%B9_%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D1%8B_%D0%B1%D0%B5%D0%BB%D0%BA%D0%BE%D0%B2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install biopython pandas numpy scikit-learn\n"
      ],
      "metadata": {
        "id": "KSFQ5RPjFCo-",
        "outputId": "0a98f321-f13a-4128-a62d-fb78cc4da6b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biopython\n",
            "  Downloading biopython-1.83-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Installing collected packages: biopython\n",
            "Successfully installed biopython-1.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import SeqIO\n",
        "from Bio.PDB import PDBList\n",
        "\n",
        "# Скачивание PDB файла\n",
        "pdb_id = '1TUP'  # Пример PDB ID\n",
        "pdbl = PDBList()\n",
        "pdbl.retrieve_pdb_file(pdb_id, file_format='pdb')\n"
      ],
      "metadata": {
        "id": "eEu-55_aFIDc",
        "outputId": "cc9c039f-dd77-42d4-e26c-a098369a0a57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading PDB structure '1tup'...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/tu/pdb1tup.ent'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from Bio.PDB import PDBParser\n",
        "from Bio import BiopythonWarning\n",
        "import numpy as np\n",
        "from Bio.PDB import PDBParser, PDBList\n",
        "import gzip\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "\n",
        "warnings.simplefilter('ignore', BiopythonWarning)\n",
        "\n",
        " # Извлечение аминокислотных последовательностей\n",
        "def extract_sequence(pdb_file):\n",
        "    parser = PDBParser()\n",
        "    structure = parser.get_structure('structure', pdb_file)\n",
        "    sequences = []\n",
        "\n",
        "    for model in structure:\n",
        "        for chain in model:\n",
        "            sequence = ''.join([residue.get_resname() for residue in chain if residue.get_id()[0] == ' '])\n",
        "            sequences.append(sequence)\n",
        "\n",
        "    return sequences\n",
        "\n",
        "sequences = extract_sequence(f'pdb1tup.ent')\n",
        "print(sequences)"
      ],
      "metadata": {
        "id": "pamwX5HBQYVy",
        "outputId": "6087a1e3-51f7-4fe5-cad5-c37eb1a33fba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'pdb1tup.ent'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4bade653f827>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0msequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'pdb1tup.ent'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-4bade653f827>\u001b[0m in \u001b[0;36mextract_sequence\u001b[0;34m(pdb_file)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdb_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPDBParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mstructure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'structure'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdb_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0msequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/Bio/PDB/PDBParser.py\u001b[0m in \u001b[0;36mget_structure\u001b[0;34m(self, id, file)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructure_builder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mas_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                 \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/Bio/File.py\u001b[0m in \u001b[0;36mas_handle\u001b[0;34m(handleish, mode, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandleish\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pdb1tup.ent'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from Bio.PDB import PDBParser\n",
        "from Bio import BiopythonWarning\n",
        "import numpy as np\n",
        "from Bio.PDB import PDBParser, PDBList\n",
        "import gzip\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "\n",
        "warnings.simplefilter('ignore', BiopythonWarning)\n",
        "\n",
        "\n",
        "# Извлечение аминокислотных последовательностей\n",
        "def extract_sequence(pdb_file):\n",
        "    parser = PDBParser()\n",
        "    structure = parser.get_structure('structure', pdb_file)\n",
        "    sequences = []\n",
        "\n",
        "    for model in structure:\n",
        "        for chain in model:\n",
        "            sequence = ''.join([residue.get_resname() for residue in chain if residue.get_id()[0] == ' '])\n",
        "            sequences.append(sequence)\n",
        "\n",
        "    return sequences\n",
        "\n",
        "sequences = extract_sequence(f'pdb1tup.ent')\n",
        "\n",
        "# Преобразование последовательностей в one-hot encoding\n",
        "amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
        "aa_to_idx = {aa: idx for idx, aa in enumerate(amino_acids)}\n",
        "\n",
        "def one_hot_encode_sequence(sequence):\n",
        "    encoding = np.zeros((len(sequence), len(amino_acids)), dtype=int)\n",
        "    for i, aa in enumerate(sequence):\n",
        "        if aa in aa_to_idx:\n",
        "            encoding[i, aa_to_idx[aa]] = 1\n",
        "    return encoding\n",
        "\n",
        "encoded_sequences = [one_hot_encode_sequence(seq) for seq in sequences]\n",
        "\n",
        "# Извлечение координат атомов\n",
        "def extract_coordinates(pdb_file):\n",
        "    parser = PDBParser()\n",
        "    structure = parser.get_structure('structure', pdb_file)\n",
        "    coordinates = []\n",
        "\n",
        "    for model in structure:\n",
        "        for chain in model:\n",
        "            chain_coords = []\n",
        "            for residue in chain:\n",
        "                if 'CA' in residue:  # Используем только C-альфа атомы\n",
        "                    atom = residue['CA']\n",
        "                    chain_coords.append(atom.coord)\n",
        "            coordinates.append(chain_coords)\n",
        "\n",
        "    return coordinates\n",
        "\n",
        "coordinates = extract_coordinates(f'pdb1tup.ent')\n",
        "\n",
        "# Преобразование координат в numpy массив\n",
        "encoded_coordinates = [np.array(coords) for coords in coordinates]\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = np.array(encoded_sequences, dtype=object)\n",
        "y = np.array(encoded_coordinates, dtype=object)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Сохранение данных в файлы\n",
        "import pickle\n",
        "\n",
        "with open('X_train.pkl', 'wb') as f:\n",
        "    pickle.dump(X_train, f)\n",
        "\n",
        "with open('X_test.pkl', 'wb') as f:\n",
        "    pickle.dump(X_test, f)\n",
        "\n",
        "with open('y_train.pkl', 'wb') as f:\n",
        "    pickle.dump(y_train, f)\n",
        "\n",
        "with open('y_test.pkl', 'wb') as f:\n",
        "    pickle.dump(y_test, f)\n"
      ],
      "metadata": {
        "id": "TL8jBIi-FVPI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pickle\n",
        "\n",
        "# Функция для паддинга последовательностей до одинаковой длины\n",
        "def pad_sequences(sequences, max_len, pad_value=0):\n",
        "    padded_sequences = np.full((len(sequences), max_len, sequences[0].shape[1]), pad_value)\n",
        "    for i, seq in enumerate(sequences):\n",
        "        padded_sequences[i, :len(seq)] = seq\n",
        "    return padded_sequences\n",
        "\n",
        "# Функция для паддинга координат до одинаковой длины\n",
        "def pad_coordinates(coordinates, max_len, pad_value=0.0):\n",
        "    padded_coordinates = np.full((len(coordinates), max_len, 3), pad_value)\n",
        "    for i, coord in enumerate(coordinates):\n",
        "        if len(coord) > 0:\n",
        "            padded_coordinates[i, :len(coord)] = coord\n",
        "    return padded_coordinates\n",
        "\n",
        "\n",
        "# Загрузка данных\n",
        "with open('X_train.pkl', 'rb') as f:\n",
        "    X_train = pickle.load(f)\n",
        "with open('X_test.pkl', 'rb') as f:\n",
        "    X_test = pickle.load(f)\n",
        "with open('y_train.pkl', 'rb') as f:\n",
        "    y_train = pickle.load(f)\n",
        "with open('y_test.pkl', 'rb') as f:\n",
        "    y_test = pickle.load(f)\n",
        "\n",
        "# Найдем максимальную длину последовательности и координат\n",
        "max_seq_len = max(max(len(seq) for seq in X_train), max(len(seq) for seq in X_test))\n",
        "max_coord_len = max(max(len(coord) for coord in y_train), max(len(coord) for coord in y_test))\n",
        "\n",
        "# Паддинг последовательностей\n",
        "X_train_padded = pad_sequences(X_train, max_seq_len)\n",
        "X_test_padded = pad_sequences(X_test, max_seq_len)\n",
        "\n",
        "# Паддинг координат\n",
        "y_train_padded = pad_coordinates(y_train, max_coord_len)\n",
        "y_test_padded = pad_coordinates(y_test, max_coord_len)\n",
        " # Преобразование данных в формат PyTorch\n",
        "X_train_tensor = torch.tensor(X_train_padded, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train_padded.reshape(len(y_train_padded), -1), dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test_padded, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test_padded.reshape(len(y_test_padded), -1), dtype=torch.float32)\n",
        "\n",
        "\n",
        "# Создание DataLoader\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Класс модели RNN\n",
        "class ProteinRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
        "        super(ProteinRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        out = self.fc(out[:, -1, :])  # берем последнее временное значение\n",
        "        return out\n",
        "\n",
        "# Гиперпараметры\n",
        "input_size = len(amino_acids)  # размер one-hot encoding для аминокислот\n",
        "hidden_size = 128\n",
        "output_size = y_train_tensor.shape[1]  # количество координат (3 * число атомов)\n",
        "num_layers = 2\n",
        "num_epochs = 3\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Инициализация модели, функции потерь и оптимизатора\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = ProteinRNN(input_size, hidden_size, output_size, num_layers).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Обучение модели\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for i, (inputs, targets) in enumerate(train_loader):\n",
        "        # Перемещение данных на устройство (CPU/GPU)\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Обнуление градиентов\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Прямой проход\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Вычисление функции потерь\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Обратный проход и оптимизация\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Сохранение обученной модели\n",
        "torch.save(model.state_dict(), 'protein_rnn_model.pth')\n",
        "\n",
        "# Функция для оценки модели\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        total_loss = 0\n",
        "        for inputs, targets in test_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(test_loader)\n",
        "\n",
        "# Оценка модели\n",
        "test_loss = evaluate_model(model, test_loader)\n",
        "print(f'Test Loss: {test_loss:.4f}')\n"
      ],
      "metadata": {
        "id": "qE8DuNhaIMoy",
        "outputId": "5c594d51-d8d2-4f0f-c110-26945ad24c99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3], Loss: 2664.6003\n",
            "Epoch [2/3], Loss: 2662.7729\n",
            "Epoch [3/3], Loss: 2660.1714\n",
            "Test Loss: 0.0403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)\n"
      ],
      "metadata": {
        "id": "DGH2simAKPqq",
        "outputId": "d66bbf21-f0c3-4474-c11e-92e9346d0c9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0]]) array([[0, 0, 0, ..., 0, 0, 0],\n",
            "                                         [0, 0, 0, ..., 0, 0, 0],\n",
            "                                         [0, 0, 0, ..., 0, 0, 0],\n",
            "                                         ...,\n",
            "                                         [0, 0, 0, ..., 0, 0, 0],\n",
            "                                         [0, 0, 0, ..., 0, 0, 0],\n",
            "                                         [0, 0, 0, ..., 0, 0, 0]])\n",
            " array([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
            "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            " array([[0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0],\n",
            "        [0, 0, 0, ..., 0, 0, 0]])]\n"
          ]
        }
      ]
    }
  ]
}